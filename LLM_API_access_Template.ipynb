{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting to LLM via API\n",
        "#### Basic template to connect with a LLM, in google colab, ask for a prompt, receive the answer in a variable and print out"
      ],
      "metadata": {
        "id": "47xsJKKV6EmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install Lamini\n",
        "#### Lamini is an LLM engine that allows any developer, not just machine learning experts, to train high-performing LLMs on large datasets using the Lamini library.\n",
        "#### Find information: https://lamini-ai.github.io/ and https://www.lamini.ai/\n",
        "This first step install the library and then import it"
      ],
      "metadata": {
        "id": "J6zZ92-A7K_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7ylj32K9O-C",
        "outputId": "505baf57-e63c-448c-ad56-6a2a61fc1083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lamini\n",
            "  Downloading lamini-2.0.13-108-py3-none-any.whl (32 kB)\n",
            "Collecting lamini-configuration[yaml] (from lamini)\n",
            "  Downloading lamini_configuration-0.8.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lamini) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lamini) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lamini) (1.25.2)\n",
            "Collecting jsonlines (from lamini)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lamini) (1.5.3)\n",
            "Collecting azure-storage-blob (from lamini)\n",
            "  Downloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lamini) (1.2.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from lamini) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (4.0.3)\n",
            "Collecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob->lamini)\n",
            "  Downloading azure_core-1.30.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (42.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (4.9.0)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob->lamini)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from lamini-configuration[yaml]->lamini) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (3.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob->lamini) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob->lamini) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->lamini) (2.21)\n",
            "Installing collected packages: lamini-configuration, jsonlines, isodate, azure-core, azure-storage-blob, lamini\n",
            "Successfully installed azure-core-1.30.0 azure-storage-blob-12.19.0 isodate-0.6.1 jsonlines-4.0.0 lamini-2.0.13 lamini-configuration-0.8.3\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade lamini"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lamini"
      ],
      "metadata": {
        "id": "CcPUpRhC9Xi5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. API key\n",
        "#### At Lamini https://app.lamini.ai/account obtain the API key"
      ],
      "metadata": {
        "id": "KJj11QbT8OD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamini.api_key = \"b29ed13c64d0e56e006ff4286605602048015db164e5b8033b60f24247d497e2\""
      ],
      "metadata": {
        "id": "v4TZTE449k9e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Connect to LLM\n",
        "#### Using Lamini´s library functions, connect to LLama2 LLM. Llama 2 is a family of pre-trained and fine-tuned large language models (LLMs) released by Meta AI in 2023.\n",
        "DEtails of how to use the library in https://lamini-ai.github.io/"
      ],
      "metadata": {
        "id": "9z1pXvcw8xdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = lamini.LlamaV2Runner()\n"
      ],
      "metadata": {
        "id": "YrxgxmQn9yfI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Prompt the LLM\n",
        "#### Now, you can send prompt to LLM, store the answer in a variable and process the answe for your own purposes"
      ],
      "metadata": {
        "id": "KyjpGis29sBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = llm(\"translate the following phrase to french: Life is a succession of lessons which must be lived to be understood\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLyFz9zx1Mb8",
        "outputId": "6138d4f3-53cd-4cac-e8c9-8ff8e6b0b1c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sure, I'd be happy to help you translate the phrase \"Life is a succession of lessons which must be lived to be understood\" into French! Here is the translation:\n",
            "\n",
            "\"La vie est une succession de leçons qui doivent être vécues pour être comprises\"\n",
            "\n",
            "In French, the phrase is \"La vie est une succession de leçons qui doivent être vécues pour être comprises.\" The word \"leçons\" means \"lessons\" in English, and \"vécues\" means \"lived.\" The phrase is saying that life is a series of lessons that must be experienced in order to be fully understood.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. A pre-tunned version\n",
        "#### In the documentation, you can find pre-tunned versions of LLama2. Let´s try one\n",
        "#### a. Connect the model\n",
        "#### b. Teach the model how to answer\n",
        "#### b. prompt the model"
      ],
      "metadata": {
        "id": "SxmcJ-aA-naq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the expected output\n",
        "data3 = [\n",
        "    [{\"input\": \"What's your favorite animal?\"}, {\"output\": \"dog\"}],\n",
        "    [{\"input\": \"What's your favorite color?\"}, {\"output\": \"blue\"}]\n",
        "]"
      ],
      "metadata": {
        "id": "Kdb_Yin_AE1-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model and learning how to answer - pairs label - answer\n",
        "llm = lamini.Lamini(model_name=\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "results = llm.train(data3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYtCZ8cAAFCs",
        "outputId": "4f42ccfc-bc5c-488f-8823-a469fb7be00d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Your dataset id is: 3104dd21f5d9913a8a89573f942253853f16d4b5062399d4bc3587003dba6c4f . Consider using this in the future to train using the same data. \n",
            "Eg: llm.train(dataset_id='3104dd21f5d9913a8a89573f942253853f16d4b5062399d4bc3587003dba6c4f')\n",
            "\n",
            "Uploading data....\n",
            "Upload to blob completed for data.\n",
            "Data pairs uploaded to blob.\n",
            "Training job submitted! Check status of job 5333 here: https://app.lamini.ai/train/5333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Send prompt, take into account that sometimes the answer could be incorrect\n",
        "# i expected Gustav Klimt, however there were many kisses in art history, who knows...\n",
        "llm.generate(\n",
        "    \"Who paint The Kiss\",\n",
        "    output_type={\"Painter\": \"str\"}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV-loZSwAFOV",
        "outputId": "b58c4ce2-f6e9-46ad-aa9f-e80cc107558a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Painter': 'Franz Kline'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another propmt\n",
        "resp = llm.generate(\n",
        "    \"the service was provided by a kind person who solved my problem, how is the sentiment?\",\n",
        "    output_type={\"service\": \"str\"})"
      ],
      "metadata": {
        "id": "FH8OesBNAcci"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUUHt4UwAcfi",
        "outputId": "53062a5b-6afe-4092-ba0b-04822b7b6dca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'service': 'helpful'}\n"
          ]
        }
      ]
    }
  ]
}